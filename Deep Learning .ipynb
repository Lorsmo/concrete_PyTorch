{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h1><h1>Pre-trained-Models with PyTorch </h1>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "In this lab, you will use pre-trained models to classify between the negative and positive samples; you will be provided with the dataset object. The particular pre-trained model will be resnet18; you will have three questions: \n<ul>\n<li>change the output layer</li>\n<li> train the model</li> \n<li>  identify  several  misclassified samples</li> \n </ul>\nYou will take several screenshots of your work and share your notebook. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2>Table of Contents</h2>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2 id=\"download_data\">Download Data</h2>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Download the dataset and unzip the files in your data directory, unlike the other labs, all the data will be deleted after you close  the lab, this may take some time:"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Positive_tensors.zip "
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "replace Positive_tensors/5114.pt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
                }
            ],
            "source": "!unzip -q Positive_tensors.zip"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "! wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/images/Negative_tensors.zip\n!unzip -q Negative_tensors.zip"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We will install torchvision:"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "!pip install torchvision"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2 id=\"auxiliary\">Imports and Auxiliary Functions</h2>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "The following are the libraries we are going to use for this lab. The <code>torch.manual_seed()</code> is for forcing the random function to give the same number every time we try to recompile it."
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "<torch._C.Generator at 0x7f7c280796d0>"
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "# These are the libraries will be used for this lab.\nimport torchvision.models as models\nfrom PIL import Image\nimport pandas\nfrom torchvision import transforms\nimport torch.nn as nn\nimport time\nimport torch \nimport matplotlib.pylab as plt\nimport numpy as np\nfrom torch.utils.data import Dataset, DataLoader\nimport h5py\nimport os\nimport glob\ntorch.manual_seed(0)"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": "from matplotlib.pyplot import imshow\nimport matplotlib.pylab as plt\nfrom PIL import Image\nimport pandas as pd\nimport os"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<!--Empty Space for separating topics-->"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2 id=\"data_class\">Dataset Class</h2>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": " This dataset class is essentially the same dataset you build in the previous section, but to speed things up, we are going to use tensors instead of jpeg images. Therefor for each iteration, you will skip the reshape step, conversion step to tensors and normalization step."
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "done\n"
                }
            ],
            "source": "# Create your own dataset object\n\nclass Dataset(Dataset):\n\n    # Constructor\n    def __init__(self,transform=None,train=True):\n        directory=\"/home/dsxuser/work\"\n        positive=\"Positive_tensors\"\n        negative='Negative_tensors'\n\n        positive_file_path=os.path.join(directory,positive)\n        negative_file_path=os.path.join(directory,negative)\n        positive_files=[os.path.join(positive_file_path,file) for file in os.listdir(positive_file_path) if file.endswith(\".pt\")]\n        negative_files=[os.path.join(negative_file_path,file) for file in os.listdir(negative_file_path) if file.endswith(\".pt\")]\n        number_of_samples=len(positive_files)+len(negative_files)\n        self.all_files=[None]*number_of_samples\n        self.all_files[::2]=positive_files\n        self.all_files[1::2]=negative_files \n        # The transform is goint to be used on image\n        self.transform = transform\n        #torch.LongTensor\n        self.Y=torch.zeros([number_of_samples]).type(torch.LongTensor)\n        self.Y[::2]=1\n        self.Y[1::2]=0\n        \n        if train:\n            self.all_files=self.all_files[0:30000]\n            self.Y=self.Y[0:30000]\n            self.len=len(self.all_files)\n        else:\n            self.all_files=self.all_files[30000:]\n            self.Y=self.Y[30000:]\n            self.len=len(self.all_files)     \n       \n    # Get the length\n    def __len__(self):\n        return self.len\n    \n    # Getter\n    def __getitem__(self, idx):\n               \n        image=torch.load(self.all_files[idx])\n        y=self.Y[idx]\n                  \n        # If there is any transform method, apply it onto the image\n        if self.transform:\n            image = self.transform(image)\n\n        return image, y\n    \nprint(\"done\")"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "We create two dataset objects, one for the training data and one for the validation data."
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "done\n30000\n10000\n"
                }
            ],
            "source": "train_dataset = Dataset(train=True)\nvalidation_dataset = Dataset(train=False)\nprint(\"done\")\nprint(len(train_dataset))\nprint(len(validation_dataset))"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2 id=\"Question_1\">Question 1</h2>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<b>Prepare a pre-trained resnet18 model :</b>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<b>Step 1</b>: Load the pre-trained model <code>resnet18</code> Set the parameter <code>pretrained</code> to true:"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": "# Step 1: Load the pre-trained model resnet18\n\n# Type your code here\nmodel = models.resnet18(pretrained=True)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<b>Step 2</b>: Set the attribute <code>requires_grad</code> to <code>False</code>. As a result, the parameters will not be affected by training."
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": "# Step 2: Set the parameter cannot be trained for the pre-trained model\n\n\n# Type your code here\nfor param in model.parameters():\n    param.requires_grad=False"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<code>resnet18</code> is used to classify 1000 different objects; as a result, the last layer has 1000 outputs.  The 512 inputs come from the fact that the previously hidden layer has 512 outputs. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<b>Step 3</b>: Replace the output layer <code>model.fc</code> of the neural network with a <code>nn.Linear</code> object, to classify 2 different classes. For the parameters <code>in_features </code> remember the last hidden layer has 512 neurons."
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": "model.fc=nn.Linear(512,2)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Print out the model in order to show whether you get the correct answer.<br> <b>(Your peer reviewer is going to mark based on what you print here.)</b>"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=2, bias=True)\n)\n"
                }
            ],
            "source": "print(model)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2 id=\"Question_2\">Question 2: Train the Model</h2>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "In this question you will train your, model:"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<b>Step 1</b>: Create a cross entropy criterion function "
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": "# Step 1: Create the loss function\n\n# Type your code here\ncriterion = nn.CrossEntropyLoss()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<b>Step 2</b>: Create a training loader and validation loader object, the batch size should have 100 samples each."
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100)\nvalidation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=100) "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<b>Step 3</b>: Use the following optimizer to minimize the loss "
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": "optimizer = torch.optim.Adam([parameters  for parameters in model.parameters() if parameters.requires_grad],lr=0.001)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<!--Empty Space for separating topics-->"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "**Complete the following code to calculate  the accuracy on the validation data for one epoch; this should take about 45 minutes. Make sure you calculate the accuracy on the validation data.**"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": "n_epochs=1\nloss_list=[]\naccuracy_list=[]\ncorrect=0\nN_test=len(validation_dataset)\nN_train=len(train_dataset)\nstart_time = time.time()\n#n_epochs\n\nLoss=0\nstart_time = time.time()\nfor epoch in range(n_epochs):\n    for x, y in train_loader:\n\n        model.train() \n        #clear gradient \n        optimizer.zero_grad()\n        #make a prediction \n        z = model(x)\n        # calculate loss \n        loss = criterion(z, y)\n        # calculate gradients of parameters \n        loss.backward()\n        # update parameters \n        optimizer.step()\n        \n        loss_list.append(loss.data)\n    correct=0\n    for x_test, y_test in validation_loader:\n        # set model to eval \n        model.eval()\n        #make a prediction \n        z = model(x_test)\n        #find max \n        _, yhat = torch.max(z.data, 1)\n       \n        #Calculate misclassified  samples in mini-batch \n        correct +=(yhat==y_test).sum().item()\n        \n   \n    accuracy=correct/N_test\n    \n\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<b>Print out the Accuracy and plot the loss stored in the list <code>loss_list</code> for every iteration and take a screen shot.</b>"
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "0.9928"
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "accuracy"
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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\n",
                        "text/plain": "<Figure size 432x288 with 1 Axes>"
                    },
                    "metadata": {
                        "needs_background": "light"
                    },
                    "output_type": "display_data"
                }
            ],
            "source": "plt.plot(loss_list)\nplt.xlabel(\"iteration\")\nplt.ylabel(\"loss\")\nplt.show()\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<h2 id=\"Question_3\">Question 3:Find the misclassified samples</h2> "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<b>Identify the first four misclassified samples using the validation data:</b>"
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "sample 144 predicted value: tensor([0]) actual value:tensor([1])\nsample 479 predicted value: tensor([1]) actual value:tensor([0])\nsample 488 predicted value: tensor([0]) actual value:tensor([1])\nsample 952 predicted value: tensor([0]) actual value:tensor([1])\n"
                }
            ],
            "source": "# Plot the mis-classified samples\n\ncount = 0\n\nfor sample,(x_test, y_test) in enumerate(torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=1)):\n       \n        z = model(x_test)\n\n        #find max \n        _, yhat = torch.max(z.data, 1)\n        \n        if yhat != y_test:\n            print(f'sample {sample } predicted value: {yhat} actual value:{y_test}')\n            count += 1\n        if count >= 4:\n            break         \n\n        \n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}